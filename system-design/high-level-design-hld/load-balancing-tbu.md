# Load Balancing - TBU

## **About**

Load balancing is the process of distributing network traffic across multiple servers to ensure no single server is overwhelmed, allowing for better fault tolerance, scalability, and reliability in applications. It helps optimize resource use, minimize latency, avoid system overload, and ensure that applications remain responsive under heavy load.

## With and Without Load Balancer comparison

<figure><img src="../../.gitbook/assets/image.png" alt="" width="563"><figcaption></figcaption></figure>

<table data-full-width="true"><thead><tr><th width="196">Aspect</th><th width="353">Without Load Balancer</th><th>With Load Balancer</th></tr></thead><tbody><tr><td><strong>Traffic Distribution</strong></td><td>Requests are manually routed or hardcoded to specific services. May lead to uneven distribution.</td><td>Traffic is automatically and evenly distributed across multiple instances of the same service.</td></tr><tr><td><strong>Scalability</strong></td><td>Scaling is manual and limited to individual servers. Difficult to handle sudden traffic surges.</td><td>Seamless horizontal scaling, allowing new instances to be added dynamically to handle increased load.</td></tr><tr><td><strong>Single Point of Failure</strong></td><td>If one service instance fails, the system can experience downtime. No built-in failover mechanism.</td><td>If a service instance fails, the load balancer redirects traffic to healthy instances, ensuring high availability.</td></tr><tr><td><strong>Performance Optimization</strong></td><td>High risk of overloading certain service instances, leading to performance bottlenecks.</td><td>Optimizes performance by balancing load across multiple instances, reducing latency and improving response time.</td></tr><tr><td><strong>Fault Tolerance</strong></td><td>No automatic recovery from service failures. Manual intervention is needed.</td><td>Built-in health checks allow the load balancer to detect unhealthy instances and reroute traffic automatically.</td></tr><tr><td><strong>Session Management</strong></td><td>Session persistence is difficult without sticky sessions, which must be managed manually by clients.</td><td>Can implement session stickiness (sticky sessions) to ensure user sessions are consistently routed to the same server.</td></tr><tr><td><strong>Maintenance &#x26; Updates</strong></td><td>Service updates or maintenance often require downtime since requests cannot be easily rerouted.</td><td>Allows rolling updates and maintenance with zero downtime by rerouting traffic to available instances during updates.</td></tr><tr><td><strong>Handling Peak Load</strong></td><td>Not well-equipped to handle peak loads, resulting in downtime or degraded performance during high traffic periods.</td><td>Efficiently handles peak loads by distributing traffic evenly and scaling out instances as needed.</td></tr><tr><td><strong>Cost Efficiency</strong></td><td>Inefficient, as servers may be underutilized or over-provisioned to handle worst-case scenarios.</td><td>Optimizes resource usage by distributing traffic, potentially lowering infrastructure costs by using fewer but more efficiently used servers.</td></tr><tr><td><strong>Service Discovery</strong></td><td>Requires static IP addresses or hardcoded configurations for routing traffic to services.</td><td>Works seamlessly with service discovery mechanisms to dynamically route traffic to service instances.</td></tr></tbody></table>



